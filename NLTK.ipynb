{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# libraries importeren\n",
    "import nltk\n",
    "from nltk import CFG, grammar, parse, word_tokenize\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.parse import RecursiveDescentParser, FeatureEarleyChartParser\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "# functies uit huiswerk\n",
    "def check_sentence(parser, sentence):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Checking ife provided sentence matches the grammar:\")\n",
    "    print(sentence)\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = sentence.split()\n",
    "    tree_found = False\n",
    "    results = parser.parse(sentence)\n",
    "    for tree in results:\n",
    "        tree_found = True\n",
    "        print(tree)\n",
    "    if not tree_found:\n",
    "        print(sentence, \"Does not match the provided grammar.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    return tree_found\n",
    "\n",
    "Test1 = FeatureGrammar.fromstring(\n",
    "    # Van internet gepakt\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "# parse hier een string voor een parse tree en alternatieve zinnen\n",
    "Test1_parser = FeatureEarleyChartParser(Test1)\n",
    "# for t in Test1_parser.parse(\"I returned a book to the library\".split()):\n",
    "#     print(t)\n",
    "#\n",
    "#\n",
    "#     for t in Test1_parser.parse(\"I returned a book to the library\".split()):print(t)\n",
    "\n",
    "for s in generate(Test1, n = 10):\n",
    "   if len(list(Test1_parser.parse(s))) != 0:\n",
    "       print(' '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Thomas\n",
      "[nltk_data]     Meeusen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Thomas Meeusen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ\n",
      "['ï', 'white', 'other', 'black', 'sixteen', 'queen', 'numbered', 'top', 'square', 'special', 'same', 'own', 'mandatory', 'second', 'seventh', 'first', 'initial', 'straight', 'vertical', 'empty', 'diagonal', 'combined', 'double', 'important', 'certain', 'following', 'enemy', 'next', 'f1', 'short']\n",
      "NNP\n",
      "['»']\n",
      "NN\n",
      "['¿chess', 'game', 'player', 'beginning', 'king', 'chessboard', 'board', 'field', 'corner', 'order', 'record', 'point', 'view', 'bottom', 'row', 'columns', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'name', 'combination', 'letter', 'column', 'number', 'example', 'square', 'a1', 'move', 'exception', 'castling', 'time', 'opponent', 'piece', 'play', 'rest', 'capturing', 'start', 'arrangement', 'rook', 'knight', 'bishop', 'lady', 'note', 'setup', 'color', 'tower', 'horizontal', 'line', 'belonging', 'runner', 'jump', 'horse', 'step', 'direction', 'jumps', 'b1', 'effect', 'pawn', 'd2', 'd3', 'space', 'type', 'rokade', 'check', 'end', 'kind', 'e1', 'c1', 'd1', 'g1']\n",
      "VBZ\n",
      "['is', 'plays', 'has', 'consists', 'piece', 'contains', 'follows', 'begins', 'ends', 'moves', 'makes', 'passes', 'captures', 'does', 'strikes', 'wants', 'casts']\n",
      "DT\n",
      "['a', 'the', 'each', 'all', 'another', 'that', 'an', 'this', 'any', 'no']\n",
      "VBN\n",
      "['played', 'colored', 'laid', 'been', 'given', 'seen', 'named', 'moved', 'removed', 'left', 'captured', 'described', 'allowed', 'run', 'provided', 'done', 'met', 'attacked']\n",
      "IN\n",
      "['by', 'with', 'at', 'of', 'on', 'that', 'in', 'as', 'from', 'for', 'out', 'over', 'between', 'if', 'whether', 'during', 'after']\n",
      "CD\n",
      "['two', 'one', 'eight', '64', '1', '2', '3', '4', '5', '6', '7', '8']\n",
      "NNS\n",
      "['players', 'pieces', 'plays', 'rooks', 'bishops', 'knights', 'pawns', 'fields', 'rows', 'columns', 'moves', 'names', 'turns', 'rules', 'ladies', 'squares', 'capabilities', 'steps', 'horses', 'conditions', 'crosses', 'spaces']\n",
      "CC\n",
      "['and', 'or']\n",
      ":\n",
      "[':', ';']\n",
      ",\n",
      "[',']\n",
      "VBP\n",
      "['are', 'have', 'take', 'say', 'stand', 'differ', 'go']\n",
      "RB\n",
      "['alternately', 'so', 'then', 'not', 'right', 'also', 'again', 'diagonally', 'outward', 'horizontally', 'vertically', 'over', 'straight', 'ahead', 'yet', 'still', 'forward', 'never', 'long', 'similarly']\n",
      "MD\n",
      "['must', 'can', 'may']\n",
      "VB\n",
      "['be', 'capture', 'jump', 'contain', 'move', 'start', 'c3', 'take', 'd4', 'make', 'perform', 'cast', 'cross', 'rook']\n",
      "RP\n",
      "['out', 'over']\n",
      "EX\n",
      "['there']\n",
      "JJR\n",
      "['lower', 'tower']\n",
      "VBD\n",
      "['left', 'jumped']\n",
      "TO\n",
      "['to']\n",
      "POS\n",
      "[\"'s\"]\n",
      "PRP$\n",
      "['its', 'his', 'their']\n",
      "(\n",
      "['(']\n",
      ")\n",
      "[')']\n",
      "VBG\n",
      "['making', 'starting', 'moving', 'according', 'being', 'containing', 'depending', 'doing', 'king']\n",
      "WDT\n",
      "['that', 'which']\n",
      "WRB\n",
      "['how', 'where', 'when']\n",
      ".\n",
      "['.']\n",
      "WP\n",
      "['who']\n",
      "PRP\n",
      "['it']\n",
      "RBS\n",
      "['most']\n",
      "PDT\n",
      "['both']\n"
     ]
    }
   ],
   "source": [
    "# Gebruik deze code om woorden van de corpus te categorizeren.\n",
    "# Packages\n",
    "import nltk\n",
    "from nltk import CFG, grammar, parse, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# dictionary in het formaat: wordclass: [woord1, woord2, etc]\n",
    "chess_dictionary = dict()\n",
    "\n",
    "# toevoegen van woorden\n",
    "def add_chess_dict(rules, left, right):\n",
    "    # If the key does not already exist, initialize it with a list.\n",
    "    if left not in rules:\n",
    "        rules[left] = []\n",
    "    if right  not in rules[left]:\n",
    "        rules[left].append(right)\n",
    "\n",
    "# open hier de corpus!\n",
    "with open(\"chessrules.txt\", \"r\") as a_file:\n",
    "  # itereer door iedere lijn\n",
    "  for line in a_file:\n",
    "    stripped_line = line.strip()\n",
    "    line = word_tokenize(stripped_line)\n",
    "    tagged_line = nltk.pos_tag(line)\n",
    "    # itereer door de gemaakte pairs\n",
    "    for pairs in tagged_line:\n",
    "        add_chess_dict(chess_dictionary, pairs[1], pairs[0])\n",
    "\n",
    "# Gebruik dit voor de ouput\n",
    "for keys,values in chess_dictionary.items():\n",
    "    print(keys)\n",
    "    print(values)\n",
    "\n",
    "\n",
    "#############################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import CFG, grammar, parse, word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "f = open('chessrules.txt')\n",
    "for line in f:\n",
    "    print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Define the cfg grammar.\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> 'DT' 'NN'\n",
    "VP -> 'VB'\n",
    "VP -> 'VB' 'NN'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Make your POS sentence into a list of tokens.\n",
    "sentence = \"DT NN VB NN\".split(\" \")\n",
    "\n",
    "# Load the grammar into the ChartParser.\n",
    "cp = nltk.ChartParser(grammar)\n",
    "\n",
    "# Generate and print the nbest_parse from the grammar given the sentence tokens.\n",
    "for tree in cp.nbest_parse(sentence):\n",
    "    print (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse line 2: ADJP -> IN JJ [0.07692307692307693]\nExpected a nonterminal, found: [0.07692307692307693]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36mread_grammar\u001B[1;34m(input, nonterm_parser, probabilistic, encoding)\u001B[0m\n\u001B[0;32m   1447\u001B[0m                 \u001B[1;31m# expand out the disjunctions on the RHS\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1448\u001B[1;33m                 \u001B[0mproductions\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0m_read_production\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnonterm_parser\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprobabilistic\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1449\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36m_read_production\u001B[1;34m(line, nonterm_parser, probabilistic)\u001B[0m\n\u001B[0;32m   1386\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1387\u001B[1;33m             \u001B[0mnonterm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpos\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnonterm_parser\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpos\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1388\u001B[0m             \u001B[0mrhsides\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnonterm\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36mstandard_nonterm_parser\u001B[1;34m(string, pos)\u001B[0m\n\u001B[0;32m   1465\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1466\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Expected a nonterminal, found: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstring\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpos\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1467\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mNonterminal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Expected a nonterminal, found: [0.07692307692307693]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-25-1157f42a6fff>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"__main__\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[0mrules\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrammar_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 38\u001B[1;33m     \u001B[0mgrammar\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCFG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromstring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrules\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     39\u001B[0m     \u001B[1;31m# print(grammar)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mMT\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36mfromstring\u001B[1;34m(cls, input, encoding)\u001B[0m\n\u001B[0;32m    555\u001B[0m         \u001B[1;33m:\u001B[0m\u001B[0mparam\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mgrammar\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0meither\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mform\u001B[0m \u001B[0mof\u001B[0m \u001B[0ma\u001B[0m \u001B[0mstring\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mstrings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    556\u001B[0m         \"\"\"\n\u001B[1;32m--> 557\u001B[1;33m         start, productions = read_grammar(\n\u001B[0m\u001B[0;32m    558\u001B[0m             \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstandard_nonterm_parser\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m         )\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36mread_grammar\u001B[1;34m(input, nonterm_parser, probabilistic, encoding)\u001B[0m\n\u001B[0;32m   1448\u001B[0m                 \u001B[0mproductions\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0m_read_production\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnonterm_parser\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprobabilistic\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1449\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1450\u001B[1;33m             raise ValueError(\"Unable to parse line %s: %s\\n%s\" %\n\u001B[0m\u001B[0;32m   1451\u001B[0m                              (linenum + 1, line, e)) from e\n\u001B[0;32m   1452\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unable to parse line 2: ADJP -> IN JJ [0.07692307692307693]\nExpected a nonterminal, found: [0.07692307692307693]"
     ]
    }
   ],
   "source": [
    "from nltk import CFG\n",
    "from nltk.grammar import Nonterminal\n",
    "from nltk.parse import ViterbiParser\n",
    "from nltk.parse.generate import generate\n",
    "from random import choices\n",
    "from random import sample\n",
    "\n",
    "MT = 1\n",
    "N_SEN = 50\n",
    "grammar_path = \"grammar_rules.txt\"\n",
    "\n",
    "def generate_phrase(grammar, prod = None):\n",
    "    if not prod:\n",
    "        prod = grammar.start()\n",
    "    if prod in grammar._lhs_index:\n",
    "        # Non-terminals\n",
    "        derivations = grammar._lhs_index[prod]\n",
    "        try:\n",
    "            probabilities = [d.prob() for d in derivations]\n",
    "        except AttributeError:\n",
    "            probabilities = None\n",
    "        derivation = choices(derivations, probabilities)[0]\n",
    "        # print(derivation._rhs)\n",
    "        # input()\n",
    "        for d in derivation._rhs:\n",
    "            yield from generate_phrase(grammar, d)\n",
    "    elif prod in grammar._rhs_index:\n",
    "        # Terminals\n",
    "        yield str(prod)\n",
    "\n",
    "def generate_corpus(grammar, prod = None):\n",
    "    yield list(generate_phrase(grammar, prod))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rules = open(grammar_path).read()\n",
    "    grammar = CFG.fromstring(rules)\n",
    "    # print(grammar)\n",
    "    if MT == 1:\n",
    "        sentences = [next(generate_corpus(grammar, Nonterminal('S'))) for s in range(500)]\n",
    "        sentences = sample([s for s in sentences if 4 < len(s) < 15], N_SEN)\n",
    "        for s in sentences:\n",
    "            print(' '.join(s).lower())\n",
    "        # print(sentences)\n",
    "\n",
    "    if MT == 2:\n",
    "        sentences = sample([s for s in generate(grammar, start=Nonterminal('S'), depth = 8, n = 100)], N_SEN)\n",
    "        for s in sentences:\n",
    "            print(' '.join(s).lower())\n",
    "        # print(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[', -> ', '-LRB-', '-RRB-', '. -> ', ': -> ', 'ADJP ', 'ADVP ', 'CC ->', 'CD ->', 'DT ->', 'EX ->', 'FRAG ', 'IN ->', 'JJ ->', 'JJR -', 'MD ->', 'NML -', 'NN ->', 'NNS -', 'NP ->', 'PDT -', 'POS -', 'PP ->', 'PRP -', 'PRP$ ', 'PRT -', 'RB ->', 'RBS -', 'ROOT ', 'RP ->', 'S -> ', 'SBAR ', 'SYM -', 'TO ->', 'UCP -', 'VB ->', 'VBD -', 'VBG -', 'VBN -', 'VBP -', 'VBZ -', 'VP ->', 'WDT -', 'WHADV', 'WHNP ', 'WP ->', 'WRB -']\n",
      "{', -> ': 64, '-LRB-': 1, '-RRB-': 1, '. -> ': 2, ': -> ': 17, 'ADJP ': 13, 'ADVP ': 34, 'CC ->': 31, 'CD ->': 35, 'DT ->': 180, 'EX ->': 5, 'FRAG ': 10, 'IN ->': 127, 'JJ ->': 67, 'JJR -': 3, 'MD ->': 19, 'NML -': 2, 'NN ->': 241, 'NNS -': 47, 'NP ->': 357, 'PDT -': 1, 'POS -': 10, 'PP ->': 113, 'PRP -': 5, 'PRP$ ': 10, 'PRT -': 2, 'RB ->': 53, 'RBS -': 1, 'ROOT ': 56, 'RP ->': 2, 'S -> ': 129, 'SBAR ': 38, 'SYM -': 2, 'TO ->': 3, 'UCP -': 1, 'VB ->': 23, 'VBD -': 1, 'VBG -': 13, 'VBN -': 30, 'VBP -': 18, 'VBZ -': 65, 'VP ->': 168, 'WDT -': 8, 'WHADV': 10, 'WHNP ': 9, 'WP ->': 1, 'WRB -': 10}\n"
     ]
    }
   ],
   "source": [
    "# import nltk_main as nl\n",
    "import nltk as nltk\n",
    "from nltk import Tree\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "txt = open('chessrules.txt', 'r')\n",
    "lines = txt.readlines()\n",
    "\n",
    "# sentences = nl.get_sentences(txt)\n",
    "\n",
    "def extract_rules(lines):\n",
    "    nlp = StanfordCoreNLP('http://localhost', port=9000, timeout=30000)\n",
    "    file_in = open('grammar_rules.txt', \"w\")\n",
    "    all_rules = []\n",
    "    all_tags = []\n",
    "    count_tags = {}\n",
    "    for sentence in lines:\n",
    "        parsed = nlp.parse(sentence)\n",
    "        t = Tree.fromstring(parsed)\n",
    "        rules = t.productions()\n",
    "        for rule in rules:\n",
    "            all_rules.append(str(rule))\n",
    "            all_tags.append(str(rule)[:5])\n",
    "    unique_rules = sorted(set(all_rules))\n",
    "    print(sorted(set(all_tags)))\n",
    "    for tag in sorted(set(all_tags)):\n",
    "        count = all_tags.count(tag)\n",
    "        count_tags[tag] = count\n",
    "    print(count_tags)\n",
    "    for rule in unique_rules:\n",
    "        count = all_rules.count(rule)\n",
    "        count_tag = count_tags[rule[:5]]\n",
    "        file_in.write(rule + ' [{}]'.format(count/count_tag) + '\\n')\n",
    "    file_in.close()\n",
    "\n",
    "\n",
    "def write_grammar():\n",
    "    file_in = open('grammar_rules.txt', \"r\")\n",
    "    rules = file_in.read()\n",
    "    rules = sorted(set(rules.split('\\n')))\n",
    "    file_in.close()\n",
    "    file_out = open('Grammar_rules_pcfg.txt', \"w\")\n",
    "    for rule in rules:\n",
    "        file_out.write(rule + '\\n')\n",
    "    file_out.close()\n",
    "\n",
    "\n",
    "extract_rules(lines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Productions for FRAG do not sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-42-bb1903dd1533>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpcfg\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPCFG\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mfile\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'grammar_rules.txt'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mgrammar\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPCFG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromstring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0msentence\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mgrammar\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36mfromstring\u001B[1;34m(cls, input, encoding)\u001B[0m\n\u001B[0;32m   1261\u001B[0m             \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstandard_nonterm_parser\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprobabilistic\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1262\u001B[0m         )\n\u001B[1;32m-> 1263\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mproductions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1265\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, start, productions, calculate_leftcorners)\u001B[0m\n\u001B[0;32m   1247\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlhs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mprobs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1248\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mPCFG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEPSILON\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mp\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mPCFG\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEPSILON\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1249\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Productions for %r do not sum to 1\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mlhs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1250\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1251\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Productions for FRAG do not sum to 1"
     ]
    }
   ],
   "source": [
    "from pcfg import PCFG\n",
    "file = open('grammar_rules.txt', 'r')\n",
    "grammar = PCFG.fromstring(file)\n",
    "\n",
    "for sentence in grammar.generate(3):\n",
    "    print(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}