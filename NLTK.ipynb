{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'book', 'library'\".",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-fac45fc5a660>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;31m# parse hier een string voor een parse tree en alternatieve zinnen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[0mTest1_parser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mFeatureEarleyChartParser\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mTest1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mTest1_parser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"I returned a book to the library\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\parse\\chart.py\u001B[0m in \u001B[0;36mparse\u001B[1;34m(self, tokens, tree_class)\u001B[0m\n\u001B[0;32m   1482\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1483\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mparse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtokens\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtree_class\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mTree\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1484\u001B[1;33m         \u001B[0mchart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchart_parse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1485\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchart\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparses\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_grammar\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtree_class\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtree_class\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1486\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\parse\\earleychart.py\u001B[0m in \u001B[0;36mchart_parse\u001B[1;34m(self, tokens, trace)\u001B[0m\n\u001B[0;32m    355\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    356\u001B[0m         \u001B[0mtokens\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 357\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_grammar\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_coverage\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    358\u001B[0m         \u001B[0mchart\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_chart_class\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    359\u001B[0m         \u001B[0mgrammar\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_grammar\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\thomas meeusen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\nltk\\grammar.py\u001B[0m in \u001B[0;36mcheck_coverage\u001B[1;34m(self, tokens)\u001B[0m\n\u001B[0;32m    673\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmissing\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    674\u001B[0m             \u001B[0mmissing\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\", \"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"%r\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mw\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmissing\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 675\u001B[1;33m             raise ValueError(\n\u001B[0m\u001B[0;32m    676\u001B[0m                 \u001B[1;34m\"Grammar does not cover some of the \"\u001B[0m \u001B[1;34m\"input words: %r.\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mmissing\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    677\u001B[0m             )\n",
      "\u001B[1;31mValueError\u001B[0m: Grammar does not cover some of the input words: \"'book', 'library'\"."
     ]
    }
   ],
   "source": [
    "# libraries importeren\n",
    "import nltk\n",
    "from nltk import CFG, grammar, parse, word_tokenize\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.parse import RecursiveDescentParser, FeatureEarleyChartParser\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "# functies uit huiswerk\n",
    "def check_sentence(parser, sentence):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Checking ife provided sentence matches the grammar:\")\n",
    "    print(sentence)\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = sentence.split()\n",
    "    tree_found = False\n",
    "    results = parser.parse(sentence)\n",
    "    for tree in results:\n",
    "        tree_found = True\n",
    "        print(tree)\n",
    "    if not tree_found:\n",
    "        print(sentence, \"Does not match the provided grammar.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    return tree_found\n",
    "\n",
    "Test1 = FeatureGrammar.fromstring(\n",
    "    \"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det Nom\n",
    "    NP -> Pro\n",
    "    NP -> PN\n",
    "    Nom -> N\n",
    "    Nom -> Nom PP\n",
    "    VP -> V NP\n",
    "    VP -> V PP\n",
    "    VP -> V NP PP\n",
    "    PP -> P NP\n",
    "\n",
    "    N[NUM=sg] -> \"toren\"|\"koning\"|\"dame\"|\"pion\"|\"paard\"|\"loper\"|\"tegenstander\"|\"pat\"\n",
    "    N[NUM=pl] ->\n",
    "    V -> \"is\"| \"read\"|\"returned\"\n",
    "    Pro -> \"I\"|\"you\"\n",
    "    PN -> \"FST\"|\"Linguistics\"\n",
    "    Det -> \"the\"|\"this\"|\"a\"\n",
    "    P -> \"to\"|\"about\"|\"in\"|\"on\"\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "# parse hier een string voor een parse tree en alternatieve zinnen\n",
    "Test1_parser = FeatureEarleyChartParser(Test1)\n",
    "for t in Test1_parser.parse(\"I returned a book to the library\".split()):\n",
    "    print(t)\n",
    "\n",
    "\n",
    "    for t in Test1_parser.parse(\"I returned a book to the library\".split()):print(t)\n",
    "\n",
    "    for s in generate(Test1, n = 10):\n",
    "       if len(list(Test1_parser.parse(s))) != 0:\n",
    "           print(' '.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Thomas\n",
      "[nltk_data]     Meeusen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Thomas Meeusen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ\n",
      "['ï', 'white', 'other', 'black', 'sixteen', 'queen', 'numbered', 'top', 'square', 'special', 'same', 'own', 'mandatory', 'second', 'seventh', 'first', 'initial', 'straight', 'vertical', 'empty', 'diagonal', 'combined', 'double', 'important', 'certain', 'following', 'enemy', 'next', 'f1', 'short']\n",
      "NNP\n",
      "['»', 'Ô¯utward']\n",
      "NN\n",
      "['¿chess', 'game', 'player', 'beginning', 'king', 'chessboard', 'board', 'field', 'corner', 'order', 'record', 'point', 'view', 'bottom', 'row', 'columns', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'name', 'combination', 'letter', 'column', 'number', 'example', 'square', 'a1', 'move', 'exception', 'castling', 'time', 'opponent', 'piece', 'play', 'rest', 'capturing', 'start', 'arrangement', 'rook', 'knight', 'bishop', 'lady', 'note', 'setup', 'color', 'tower', 'horizontal', 'line', 'belonging', 'runner', 'jump', 'horse', 'step', 'direction', 'jumps', 'b1', 'effect', 'pawn', 'd2', 'd3', 'space', 'type', 'rokade', 'check', 'end', 'kind', 'e1', 'c1', 'd1', 'g1']\n",
      "VBZ\n",
      "['is', 'plays', 'has', 'consists', 'piece', 'contains', 'follows', 'begins', 'ends', 'moves', 'makes', 'passes', 'captures', 'does', 'strikes', 'wants', 'casts']\n",
      "DT\n",
      "['a', 'the', 'each', 'all', 'another', 'that', 'an', 'this', 'any', 'no']\n",
      "VBN\n",
      "['played', 'colored', 'laid', 'been', 'given', 'seen', 'named', 'moved', 'removed', 'left', 'captured', 'described', 'allowed', 'run', 'provided', 'done', 'met', 'attacked']\n",
      "IN\n",
      "['by', 'with', 'at', 'of', 'on', 'that', 'in', 'as', 'from', 'for', 'out', 'over', 'between', 'if', 'whether', 'during', 'after']\n",
      "CD\n",
      "['two', 'one', 'eight', '64', '1', '2', '3', '4', '5', '6', '7', '8']\n",
      "NNS\n",
      "['players', 'pieces', 'plays', 'rooks', 'bishops', 'knights', 'pawns', 'fields', 'rows', 'columns', 'moves', 'names', 'turns', 'rules', 'ladies', 'squares', 'capabilities', 'steps', 'horses', 'conditions', 'crosses', 'spaces']\n",
      "CC\n",
      "['and', 'or']\n",
      ":\n",
      "[':', ';']\n",
      ",\n",
      "[',']\n",
      "VBP\n",
      "['are', 'have', 'take', 'say', 'stand', 'differ', 'go']\n",
      "RB\n",
      "['alternately', 'so', 'then', 'not', 'right', 'also', 'again', 'diagonally', 'horizontally', 'vertically', 'over', 'straight', 'ahead', 'yet', 'still', 'forward', 'never', 'long', 'similarly']\n",
      "MD\n",
      "['must', 'can', 'may']\n",
      "VB\n",
      "['be', 'capture', 'jump', 'contain', 'move', 'start', 'c3', 'take', 'd4', 'make', 'perform', 'cast', 'cross', 'rook']\n",
      "RP\n",
      "['out', 'over']\n",
      "EX\n",
      "['there']\n",
      "JJR\n",
      "['lower', 'tower']\n",
      "VBD\n",
      "['left', 'jumped']\n",
      "TO\n",
      "['to']\n",
      "POS\n",
      "[\"'s\", \"'\"]\n",
      "PRP$\n",
      "['its', 'his', 'their']\n",
      "(\n",
      "['(']\n",
      ")\n",
      "[')']\n",
      "VBG\n",
      "['making', 'starting', 'moving', 'according', 'being', 'containing', 'depending', 'doing', 'king']\n",
      "WDT\n",
      "['that', 'which']\n",
      "WRB\n",
      "['how', 'where', 'when']\n",
      ".\n",
      "['.']\n",
      "WP\n",
      "['who']\n",
      "PRP\n",
      "['it']\n",
      "RBS\n",
      "['most']\n",
      "PDT\n",
      "['both']\n"
     ]
    }
   ],
   "source": [
    "# Gebruik deze code om woorden van de corpus te categorizeren.\n",
    "# Packages\n",
    "import nltk\n",
    "from nltk import CFG, grammar, parse, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# dictionary in het formaat: wordclass: [woord1, woord2, etc]\n",
    "chess_dictionary = dict()\n",
    "\n",
    "# toevoegen van woorden\n",
    "def add_chess_dict(rules, left, right):\n",
    "    # If the key does not already exist, initialize it with a list.\n",
    "    if left not in rules:\n",
    "        rules[left] = []\n",
    "    if right  not in rules[left]:\n",
    "        rules[left].append(right)\n",
    "\n",
    "# open hier de corpus!\n",
    "with open(\"chessrules.txt\", \"r\") as a_file:\n",
    "  # itereer door iedere lijn\n",
    "  for line in a_file:\n",
    "    stripped_line = line.strip()\n",
    "    line = word_tokenize(stripped_line)\n",
    "    tagged_line = nltk.pos_tag(line)\n",
    "    # itereer door de gemaakte pairs\n",
    "    for pairs in tagged_line:\n",
    "        add_chess_dict(chess_dictionary, pairs[1], pairs[0])\n",
    "\n",
    "# Gebruik dit voor de ouput\n",
    "for keys,values in chess_dictionary.items():\n",
    "    print(keys)\n",
    "    print(values)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import CFG, grammar, parse, word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "f = open('chessrules.txt')\n",
    "for line in f:\n",
    "    print(line.strip())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = word_tokenize(\"the king and the queens\")\n",
    "print(nltk.pos_tag(text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}